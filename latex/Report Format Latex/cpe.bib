

@misc{a,
  author = {K. Fosu},
  title = {How Unintentional Repetition Hurts Your Writing},
  howpublished = "Available at \url{https://medium.com/the-brave-writer/how-repetition-hurts-your-writing-cb68c292525f}",
  year = {2020}, 
  note = "[Online; accessed October 2022]"
}


@article{ b,
  author =	 {J. Piskorski and N. Stefanovitch and G. Jacquet and A. Podavini},
  title =	 {Exploring Linguistically-Lightweight Keyword Extraction Techniques for Indexing News Articles in a Multilingual Set-up},
  journal =	 {Aclanthology},
}

@misc{c,
  author = {IBM},
  title = {Natural Language Processing (NLP)},
  howpublished = "Available at \url{https://www.ibm.com/cloud/learn/natural-language-processing}" ,
  year = {2020}, 
  note = "[Online; accessed October 2022]"
}

@misc{d,
  author = {R. Horev},
  title = {BERT Explained: State of the art language model for NLP},
  howpublished = "Available at \url{https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270}",
  year = {2018}, 
  note = "[Online; accessed October 2022]"
}

@misc{e,
  author = {D. Jurafsky and J.H. Martin},
  title = { Vector Semantics and Embeddings},
  howpublished = "Available at \url{https://web.stanford.edu/~jurafsky/slp3/6.pdf}",
  year = {2021}, 
  note = "[Online; accessed October 2022]"
}

@misc{f,
  author = {T. Pradeep},
  title = {  Keyword Extraction Methods from Document in NLP },
  howpublished = "Available at \url{https://www.analyticsvidhya.com/blog/2022/03/keyword-extraction-methods-from-documents-in-nlp/}",
  year = {2022}, 
  note = "[Online; accessed October 2022]"
}

@misc{g,
  author = {Prowritingaid},
  title = {  What makes ProWritingAid different? },
  howpublished = "Available at \url{https://prowritingaid.com/}",
  note = "[Online; accessed October 2022]"
}
@misc{h,
  author = {Grammarly},
  title = {  About Grammarly },
  howpublished = "Available at \url{https://www.grammarly.com/about}",
  note = "[Online; accessed October 2022]"
}

@misc{i,
  author = {Writer.com},
  title = {  Product Overview },
  howpublished = "Available at \url{https://writer.com/product/overview/}",
  note = "[Online; accessed October 2022]"
}



@Article{j,
  author = 	 {J. Devlin and M. Chang and K. Lee and K. Toutanova},
  title = 	 {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  journal = 	 arXiv,
  year = 	 2019,
}

@Article{k,
  author = 	 {W. Zhou and T. Ge and W. Xu and W. Faru and Z. Ming},
  title = 	 { BERT-based Lexical Substitution},
  journal = 	 {ACL Anthology},

}

@Article{l,
  author = 	 {J. Qiang and Y. Li and Y. Zhu},
  title = 	 {A Simple BERT-Based Approach for Lexical Simplification},
  journal = 	 {arXiv},
}

@misc{m,
  author = {U. Ankit},
  title = {  Transformer Neural Networks: A Step-by-Step Breakdown },
  howpublished = "Available at \url{https://builtin.com/artificial-intelligence/transformer-neural-network}",
  year = {2022}, 
  note = "[Online; accessed November 2022]"
}

@misc{n,
  author = {Maxime},
  title = {  What is a Transformer?
 },
  howpublished = "Available at \url{https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04}",
  year = {2019}, 
  note = "[Online; accessed November 2022]"
}

@Article{o,
  author = 	 {N. Arefyev and B. Sheludko and A. Podolskiy and A. Panchenko},
  title = 	 {Always Keep your Target in Mind: Studying Semantics and
Improving Performance of Neural Lexical Substitution},
  journal = 	 {ACL Anthology},
}

@Article{p,
  author = 	 {A. Vaswani and N. Shazeer and N. Parmar and J. Uszkoreit and L. Jones and A. N. Gomez and L. KKaiser},
  title = 	 {Attention Is All You Need},
  journal = 	 {arXiv},
}



@misc{q,
  author = {The Council of Europe},
  title = {  Common European Framework of Reference for Languages (CEFR) },
  howpublished = "Available at \url{https://www.coe.int/en/web/common-european-framework-reference-languages/table-1-cefr-3.3-common-reference-levels-global-scale}",
  note = "[Online; accessed May 2023]"
}



@Article{r,
  author = 	 {T. Tilahun Hailu and J. Yu and T. Geteye Fantaye},
  title = 	 {Intrinsic and Extrinsic Automatic Evaluation Strategies for Paraphrase Generation Systems},
  journal = 	 {Journal of Computer and Communications},
}


@misc{s,
  author = {M. Politi},
  title = {  arXiv Dataset },
  howpublished = "Available at \url{https://towardsdatascience.com/fine-tuning-for-domain-adaptation-in-nlp-c47def356fd6}",
  note = "[Online; accessed May 2023]"
}

@misc{t,
  author = {Cornell University},
  title = {  arXiv Dataset},
  howpublished = "Available at \url{https://www.kaggle.com/datasets/Cornell-University/arxiv}",
  note = "[Online; accessed May 2023]"
}


@Article{u,
  author = 	 {Y. Liu and M. Ott and N. Goyal and J. Du, Mandar Joshi and D. Chen and O. Levy and M. Lewis and L. Zettlemoyer and V.Stoyanov},
  title = 	 {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  journal = 	 {arXiv},
}

@inproceedings{v,
  title={Connector Usage in the English Essay Writing of Japanese EFL Learners.},
  author={Narita, Masumi and Sato, Chieko and Sugiura, Masatoshi},
  booktitle={LREC},
  volume={27},
  pages={1171--1174},
  year={2004},
  organization={Citeseer}
}

@article{w,
  title={An investigation into the difficulties of using transitional words in Kurdish EFL studentsâ€™ writing at the university level},
  author={Hama, Farhad M},
  journal={UKH Journal of Social Sciences},
  volume={5},
  number={1},
  pages={107--117},
  year={2021}
}

@misc{x,
  author = {E. Munawwar},
  title = { A comprehensive guide to subword tokenisers
},
  howpublished = "Available at \url{https://towardsdatascience.com/a-comprehensive-guide-to-subword-tokenisers-4bbd3bad9a7c}",
  note = "[Online; accessed May 2023]"
}

@misc{y,
  author = {D. Lippman},
  title = { Voting Theory
},
  howpublished = "Available at \url{http://www.opentextbookstore.com/mathinsociety/current/VotingTheory.pdf}",
  note = "[Online; accessed May 2023]"
}
