

@misc{a,
  author = {Fosu K.},
  title = {How Unintentional Repetition Hurts Your Writing},
  howpublished = "Available at \url{https://medium.com/the-brave-writer/how-repetition-hurts-your-writing-cb68c292525f}",
  year = {2020}, 
  note = "[Online; accessed October 2022]"
}


@article{ b,
  author =	 {Piskorski J. and Stefanovitch N. and Jacquet  G. and Podavini, A},
  title =	 {Exploring Linguistically-Lightweight Keyword Extraction Techniques for Indexing News Articles in a Multilingual Set-up},
  journal =	 {Aclanthology},
}

@misc{c,
  author = {IBM},
  title = {Natural Language Processing (NLP)},
  howpublished = "Available at \url{https://www.ibm.com/cloud/learn/natural-language-processing}" ,
  year = {2020}, 
  note = "[Online; accessed October 2022]"
}

@misc{d,
  author = {Horev, R},
  title = {BERT Explained: State of the art language model for NLP},
  howpublished = "Available at \url{https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270}",
  year = {2018}, 
  note = "[Online; accessed October 2022]"
}

@misc{e,
  author = {Jurafsky, D. and Martin, J.H},
  title = { Vector Semantics and Embeddings},
  howpublished = "Available at \url{https://web.stanford.edu/~jurafsky/slp3/6.pdf}",
  year = {2021}, 
  note = "[Online; accessed October 2022]"
}

@misc{f,
  author = {Pradeep, T},
  title = {  Keyword Extraction Methods from Document in NLP },
  howpublished = "Available at \url{https://www.analyticsvidhya.com/blog/2022/03/keyword-extraction-methods-from-documents-in-nlp/}",
  year = {2022}, 
  note = "[Online; accessed October 2022]"
}

@misc{g,
  author = {Prowritingaid},
  title = {  What makes ProWritingAid different? },
  howpublished = "Available at \url{https://prowritingaid.com/}",
  note = "[Online; accessed October 2022]"
}
@misc{h,
  author = {Grammarly},
  title = {  About Grammarly },
  howpublished = "Available at \url{https://www.grammarly.com/about}",
  note = "[Online; accessed October 2022]"
}

@misc{i,
  author = {Writer.com},
  title = {  Product Overview },
  howpublished = "Available at \url{https://writer.com/product/overview/}",
  note = "[Online; accessed October 2022]"
}



@Article{j,
  author = 	 {Devlin J. and Chang M. and Lee K. and Toutanova K.},
  title = 	 {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  journal = 	 arxiv.org,
  year = 	 2019,
}

@Article{k,
  author = 	 {Zhou W and Ge T and Xu K and Faru W and Ming Zhou},
  title = 	 { BERT-based Lexical Substitution},
  journal = 	 {Aclanthology},

}

@Article{l,
  author = 	 {Jipeng Qiang, Yun Li, Yi Zhu},
  title = 	 {A Simple BERT-Based Approach for Lexical Simplification},
  journal = 	 {arxiv},
}

@misc{m,
  author = {Utkarsh Ankit},
  title = {  Transformer Neural Networks: A Step-by-Step Breakdown },
  howpublished = "Available at \url{https://builtin.com/artificial-intelligence/transformer-neural-network}",
  year = {2022}, 
  note = "[Online; accessed November 2022]"
}

@misc{n,
  author = {Maxime},
  title = {  What is a Transformer?
 },
  howpublished = "Available at \url{https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04}",
  year = {2019}, 
  note = "[Online; accessed November 2022]"
}








